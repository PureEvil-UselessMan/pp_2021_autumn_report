\documentclass{report}

\usepackage[warn]{mathtext}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage{tempora}
\usepackage[12pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{amsmath}

\geometry{a4paper,top=2.3cm,bottom=2.3cm,left=2.5cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\usepackage{listings}
\lstset{language=C++,
        basicstyle=\footnotesize,
		keywordstyle=\color{blue}\ttfamily,
		stringstyle=\color{red}\ttfamily,
		commentstyle=\color{green}\ttfamily,
		morecomment=[l][\color{red}]{\#}, 
		tabsize=4,
		breaklines=true,
  		breakatwhitespace=true,
  		title=\lstname,       
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother

\begin{document}

\begin{titlepage}
\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}
\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}
\begin{center}
Институт информационных технологий, математики и механики
\end{center}
\vspace{4em}
\begin{center}
\textbf{\LargeОтчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\Large«Поразрядная сортировка для вещественных чисел (тип double) 
с четно-нечетным слиянием Бэтчера.»} \\
\end{center}
\vspace{4em}
\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнила:} \\ студентка группы 381906-2 \\ Барышева М. А.\\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А. В.\\
}
\vspace{\fill}
\begin{center} Нижний Новгород \\ 2021 \end{center}
\end{titlepage}
\setcounter{page}{2}
\tableofcontents
\newpage
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
\par 
Поразрядная сортировка – алгоритм сортировки, идея которого состоит в разделении элементов на старшие и младшие разряды. При данной сортировке
сначала сравниваются и сортируются между собой значения, стоящие в младших разрядах. После этого процедура сравнения повторяется для старших разрядов.
Лабораторная работа направлена на реализацию параллельного алгоритма
сортировки, а именно - поразрядной сортировки типа double с чётно-нечётным слиянием Бэтчера, а также сравнение ее производительности с последовательной поразрядной. сортировкой
Данный алгоритм будет состоять из следующих шагов:
\begin{enumerate}
\item Сортировка частей массива.
\item Слияние отсортированных частей массива.
\end{enumerate}
Более подробно о каждом из этих шагов, будет рассказано позднее в описании
алгоритмов. Так же будет приведён пример сортировки.
\newpage
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}
\par В данном лабораторной работе требуется реализовать последовательный и параллельный алгоритмы поразрядкой сортировки для чисел типа double и реализовать четно-нечетное слияние Бэтчера. Нужно провести тесты для сравнения времени работы алгоритмов, используя при этом модуль для тестирования Google Test и сделать выводы об эффективности реализованных алгоритмов на основании результатов тестов.
Параллельный алгоритм должен быть реализован при помощи интерфейса передачи MPI.
\newpage
\section*{Описание алгоритма}
\addcontentsline{toc}{section}{Описание алгоритма}
\par Поразрядная сортировка, как уже было сказано ранее, заключается в том, что выполняется последовательная сортировка чисел по разрядам (от младшего разряда к старшему). Числа представлены битах и байтах, например, в побайтовой реализации число будет выглядеть как набор 256-значных цифр. Отметим, что данная сортировка работает именно на числах 2 в степени [прим. именно моя реализация алгоритма].
Сортировка будет проходить в несколько этапов:
\begin{enumerate} 
 \item Создается счетчик проходов по массиву count;
\item Осуществляется проход по массиву, сравниваются значения одного крайнего разряда, и элементы группируются по результатам этого сравнения;
\item Сравниваются значения следующего разряда, соседнего, и элементы либо упорядочиваются по результатам сравнения значений этого разряда внутри образованных на предыдущем проходе групп, либо переупорядочиваются в целом, но сохраняя относительный порядок, достигнутый при предыдущей сортировке. Затем аналогично делается для следующего разряда, и так до конца.
\end{enumerate}
Отрицательные числа этой реализации поначалу расположены в обратном порядке, поэтому при вычислении их расположения необходимо идти от count[255]=0, соответствующего наименьшему отрицательному числу до count[128]. При этом в массив нужно записывать сумму всех чисел после текущего, включая само текущее. Положительные числа идут от [0] до [128].
Идея четно-нечетного слияния Бэтчера заключается в том, что два упорядоченных
массива, которые необходимо слить, разделяются на четные и нечетные элементы, выполняется слияние отдельно четных и нечетных элементов. А после реализуется слияние четных и нечетных частей в одну. Чтобы массив стал окончательно
отсортированным, достаточно сравнить пары элементов, стоящие на нечетной и четной
позициях.
\newpage
\section*{Описание схемы распараллеливания}
\addcontentsline{toc}{section}{Описание схемы распараллеливания}
\par Сначала мы получаем количество и ранг каждого процесса, далее разбиваем массив на подмассивы и отправляем процессам с помощью MPI\_Scatter. Каждый процесс поразрядной сортировкой сортирует свой подмассив.
Прием отсортированных подмассивов осуществляем с помощью MPI\_Recv.
\newpage
\section*{Описание программной реализации}
\addcontentsline{toc}{section}{Описание программной реализации}
Программа состоит из заголовочного файла radix\_batcher.h и двух файлов .cpp radix\_batcher.cpp и main.cpp. В заголовочном файле находятся прототипы функций для последовательного и параллельного алгоритмов, а также вспомогательные функции. В файле radix\_batcher.cpp содержится реализация функций, объявленных в заголовочном файле. В файле main.cpp содержатся тесты для проверки корректности программы.
\begin{enumerate}
\item std::vector<double> getRandomVector(int sz); -- возвращает случайный вектор размера size.
\item void createCounters(T *data, uint64\_t *counters, uint64\_t N) --
\item void radixPass(uint16\_t Offset, uint64\_t N, T *source, T *dest, uint64\_t *count) -- выполняет проход по младшим разрядам чисел.
\item void floatRadixLastPass(uint16\_t Offset, uint64\_t N, T *source, T *dest, uint64\_t *count) -- выполняет проход по старшим разрядам чисел.
\item void floatRadixSort(T **in, uint64\_t N) -- выполняет сортировку сначала для младших разрядов, затем для старших, используя функции выше.
\item void oddEvenMerge(std::vector<double> *arr, int n, int lo = 0, int r = 1); -- выполняет сравнение четных или нечетных элементов элементов массива.
\item std::vector<double> RadixSortParallel(std::vector<double> arr, int size); --выполняет параллельную поразрядную сортировку для вещественных чисел типа double.
\item std::vector<double> merge(std::vector<std::vector<double>> vectorOfVal); -- выполняет слияние четных и нечетных элементов массива после выполнения функции oddEvenMerge.
\end{enumerate}
\newpage
\section*{Подтверждение корректности}
\addcontentsline{toc}{section}{Подтверждение корректности}
Для подтверждения корректности в программе реализован набор тестов с использованием модуля для тестирования Google Testing Framework для C++.
Тесты проверяют корректную работу последовательного и параллельного алгоритмов
сортировки на массивах разного размера и сравнивают полученные результаты с помощью командф EXPECT\_TRUE. \\
Тесты работают корректно, что говорит о верной реализации программы.
\newpage
\section*{Результаты экспериментов}
\addcontentsline{toc}{section}{Результаты экспериментов}
Тесты проводились на ПК с следующей конфигурацией:
\begin{itemize}
\item Процессор: Intel Core i5 3210M, 2x2.5 ГГц;
\item Оперативная память: 8 ГБ;
\item Операционная система: Windows 8;
\item Версия Visual Studio: 2019.
\end{itemize}
На таблице ниже приведены результаты тестов на различных числах процессов и различных размерах массивов.
\begin{table}[!h]
\begin{tabular}{| p{2cm} | p{2cm} | p{3cm} | p{3cm} | p{3cm} |}
\hline
Количество процессов & Размер массива & Время работы последовательного алгоритма & Время работы параллельного алгоритма & Эффективность  \\[5pt]
\hline
1 &   1024    & 0.000289423        & 0.000368645     & 0.785078       \\
1  & 2048     & 0.000408066        & 0.000407613     & 1.001111       \\
4    & 1048576    & 0.150877        & 0.0716139     & 2.10681       \\
4   &  16777216   & 2.79314        & 1.33439     & 2.0932      \\
8    & 65536   & 0.0079241        & 0.0059261     & 1.33715       \\
8   &  1048576   & 0.159592        & 0.0675455     & 2.362273       \\
\hline
\end{tabular}
\end{table}
\newpage
\section*{Выводы из результатов экспериментов}
\addcontentsline{toc}{section}{Выводы из результатов экспериментов}
По данным экспериментов можно отметить, что использование параллельной поразрядной
сортировки для вещественных (типа double) чисел с четно-нечетным слиянием Бэтчера более эффективно, чем использование последовательного алгоритма поразрядной сортировки, но только на больших размерах массивов.
\newpage
% Заключение
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
В ходе лабораторной работы были реализованы два алгоритма сортировки массивов для вещественных чисел типа double с четно-нечетным слиянием Бэтчера:
последовательная поразрядная сортировка и параллельная поразрядная сортировка. Тесты показали, что последовательный алгоритм уступает в эффективности параллельному алгоритму, так как работает медленнее при большем объеме данных. Этот факт делает параллельную сортировку более удобной для использования при решении сложных вычислительных задач.
\newpage
\section*{Источники}
\addcontentsline{toc}{section}{Источники}
\begin{enumerate}
\item Habr - Электронный ресурс. URL: https://habr.com/ru/post/484224/
\item Блог программиста - Электронный ресурс. URL: https://pro-prof.com/forums/topic/radix\_sort
\item Википедия - Электронный ресурс. URL: https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%80%D0%B0%D0%B7%D1%80%D1%8F%D0%B4%D0%BD%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0 
\end{enumerate} 
\newpage
\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
Заголовочный файл radix\_batcher.h:\\
\begin{lstlisting}
// Copyright 2021 Barysheva Maria
#ifndef MODULES_TASK_3_BARYSHEVA_M_RADIX_BATCHER_RADIX_BATCHER_H_
#define MODULES_TASK_3_BARYSHEVA_M_RADIX_BATCHER_RADIX_BATCHER_H_

#include <cstdint>
#include <cstring>
#include <utility>
#include <vector>

double *getRandomVector(const int size);
void RadixSortParallel(double **arr, int size);

template <class T>
void createCounters(T *data, uint64_t *counters, uint64_t N) {
  memset(counters, 0, 256 * sizeof(T) * sizeof(uint64_t));

  uint8_t *bp = reinterpret_cast<uint8_t *>(data);
  uint8_t *dataEnd = reinterpret_cast<uint8_t *>(data + N);
  uint16_t i;

  while (bp != dataEnd) {
    for (i = 0; i < sizeof(T); i++) counters[256 * i + *bp++]++;
  }
}

template <class T>
void radixPass(uint16_t Offset, uint64_t N, T *source, T *dest,
               uint64_t *count) {
  T *sp;
  uint64_t s, c, i, *cp;
  uint8_t *bp;

  s = 0;
  cp = count;
  for (i = 256; i > 0; --i, ++cp) {
    c = *cp;
    *cp = s;
    s += c;
  }

  bp = reinterpret_cast<uint8_t *>(source) + Offset;
  sp = source;
  for (i = N; i > 0; --i, bp += sizeof(T), ++sp) {
    cp = count + *bp;
    dest[*cp] = *sp;
    ++(*cp);
  }
}

template <class T>
void floatRadixLastPass(uint16_t Offset, uint64_t N, T *source, T *dest,
                        uint64_t *count) {
  T *sp;
  uint64_t s, c, i, *cp;
  uint8_t *bp;

  uint64_t numNeg = 0;
  for (i = 128; i < 256; i++) numNeg += count[i];

  s = numNeg;
  cp = count;
  for (i = 0; i < 128; ++i, ++cp) {
    c = *cp;
    *cp = s;
    s += c;
  }

  s = count[255] = 0;
  cp = count + 254;
  for (i = 254; i >= 128; --i, --cp) {
    *cp += s;
    s = *cp;
  }

  bp = reinterpret_cast<uint8_t *>(source) + Offset;
  sp = source;
  for (i = N; i > 0; --i, bp += sizeof(T), ++sp) {
    cp = count + *bp;
    if (*bp < 128)
      dest[(*cp)++] = *sp;
    else
      dest[--(*cp)] = *sp;
  }
}

template <class T>
void floatRadixSort(T **in, uint64_t N) {
  T *out = new T[N];
  uint16_t i;

  uint64_t *counters = new uint64_t[sizeof(T) * 256], *count;
  createCounters((*in), counters, N);

  for (i = 0; i < sizeof(T) - 1; i++) {
    count = counters + 256 * i;
    if (count[0] == N) continue;
    radixPass(i, N, (*in), out, count);
    std::swap((*in), out);
  }
  count = counters + 256 * i;
  floatRadixLastPass(i, N, (*in), out, count);

  delete (*in);
  (*in) = out;
  delete[] counters;
}

#endif  // MODULES_TASK_3_BARYSHEVA_M_RADIX_BATCHER_RADIX_BATCHER_H_
\end{lstlisting}
Файл реализации radix\_batcher.cpp
\begin{lstlisting}
    // Copyright 2021 Barysheva Maria
#include "../../../modules/task_3/barysheva_m_radix_batcher/radix_batcher.h"

#include <mpi.h>

#include <cmath>
#include <ctime>
#include <algorithm>
#include <random>
#include <utility>
#include <vector>

double* getRandomVector(const int size) {
  std::mt19937 gen(time(0));
  std::uniform_real_distribution<> urd(0, 300);
  double* vec = new double[size];
  for (int i = 0; i < size; i++) vec[i] = urd(gen);

  return vec;
}

double* merge(double* vec1, double* vec2, int size1, int size2) {
  int vec1_elem = 0, vec2_elem = 0, k = 0;
  double* result = new double[size1 + size2];

  while (vec1_elem < size1 && vec2_elem < size2)
    if (vec1[vec1_elem] < vec2[vec2_elem]) {
      result[k] = vec1[vec1_elem];
      vec1_elem++;
      k++;
    } else {
      result[k] = vec2[vec2_elem];
      vec2_elem++;
      k++;
    }
  if (vec1_elem == size1) {
    while (vec2_elem < size2) {
      result[k] = vec2[vec2_elem];
      vec2_elem++;
      k++;
    }
  } else {
    while (vec1_elem < size1) {
      result[k] = vec1[vec1_elem];
      vec1_elem++;
      k++;
    }
  }
  return result;
}

void RadixSortParallel(double** arr, int size_v) {
  double* chunk;
  double* other;
  int m = size_v, n = size_v;
  int rank, size;
  int delta, step = 1;

  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);

  if (rank == 0) {
    delta = n / size;

    MPI_Bcast(&delta, 1, MPI_INT, 0, MPI_COMM_WORLD);
    chunk = new double[delta];
    MPI_Scatter(*arr, delta, MPI_DOUBLE, chunk, delta, MPI_DOUBLE, 0,
                MPI_COMM_WORLD);
    floatRadixSort<double>(&chunk, delta);
  } else {
    MPI_Bcast(&delta, 1, MPI_INT, 0, MPI_COMM_WORLD);
    chunk = new double[delta];
    MPI_Scatter(*arr, delta, MPI_DOUBLE, chunk, delta, MPI_DOUBLE, 0,
                MPI_COMM_WORLD);
    floatRadixSort<double>(&chunk, delta);
  }

  while (step < size) {
    int current_rank = rank % (2 * step);
    if (current_rank == 0) {
      if (rank + step < size) {
        MPI_Recv(&m, 1, MPI_INT, rank + step, 0, MPI_COMM_WORLD,
                 MPI_STATUSES_IGNORE);
        other = new double[m];
        MPI_Recv(other, m, MPI_DOUBLE, rank + step, 0, MPI_COMM_WORLD,
                 MPI_STATUSES_IGNORE);
        chunk = merge(chunk, other, delta, m);
        delta = delta + m;
        fflush(stdout);
      }
    } else {
      int near = rank - step;
      MPI_Send(&delta, 1, MPI_INT, near, 0, MPI_COMM_WORLD);
      MPI_Send(chunk, delta, MPI_DOUBLE, near, 0, MPI_COMM_WORLD);
      break;
    }
    step = step * 2;
  }
  if (rank == 0) {
    *arr = chunk;
  }
}

\end{lstlisting}
Файл main.cpp
\begin{lstlisting}

// Copyright 2021 Barysheva Maria
#include <gtest/gtest.h>

#include <cmath>
#include <vector>
#include <gtest-mpi-listener.hpp>

#include "./radix_batcher.h"

TEST(RADIX_BATCHER, TEST_1) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (log2(size) == static_cast<int>(log2(size))) {
    double *vec, *vec_p, *vec_s;
    double start, end;
    int size_v = pow(2, 4);
    if (rank == 0) {
      std::cout << "Size: " << size_v << std::endl;
      vec = getRandomVector(size_v);
      vec_p = new double[size_v];
      vec_s = new double[size_v];
      for (int i = 0; i < size_v; i++) {
        vec_p[i] = vec[i];
        vec_s[i] = vec[i];
      }
    }
    start = MPI_Wtime();
    RadixSortParallel(&vec_p, size_v);
    end = MPI_Wtime();
    if (rank == 0) {
      double ptime = end - start;
      start = MPI_Wtime();
      floatRadixSort<double>(&vec_s, size_v);
      end = MPI_Wtime();
      double stime = end - start;
      for (int i = 0; i < size_v; i++) {
        EXPECT_DOUBLE_EQ(vec_p[i], vec_s[i]);
        // std::cout << vec[i] << " " << vec_s[i] << std::endl;
      }
      std::cout << "Parallel: " << ptime << " Sequential: " << stime
                << std::endl;
      std::cout << "Speedup: " << stime / ptime << std::endl;
    }
  }
}

TEST(RADIX_BATCHER, TEST_2) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (log2(size) == static_cast<int>(log2(size))) {
    double *vec, *vec_p, *vec_s;
    double start, end;
    int size_v = pow(2, 5);
    if (rank == 0) {
      std::cout << "Size: " << size_v << std::endl;
      vec = getRandomVector(size_v);
      vec_p = new double[size_v];
      vec_s = new double[size_v];
      for (int i = 0; i < size_v; i++) {
        vec_p[i] = vec[i];
        vec_s[i] = vec[i];
      }
    }
    start = MPI_Wtime();
    RadixSortParallel(&vec_p, size_v);
    end = MPI_Wtime();
    if (rank == 0) {
      double ptime = end - start;
      start = MPI_Wtime();
      floatRadixSort<double>(&vec_s, size_v);
      end = MPI_Wtime();
      double stime = end - start;
      for (int i = 0; i < size_v; i++) {
        EXPECT_DOUBLE_EQ(vec_p[i], vec_s[i]);
        // std::cout << vec[i] << " " << vec_s[i] << std::endl;
      }
      std::cout << "Parallel: " << ptime << " Sequential: " << stime
                << std::endl;
      std::cout << "Speedup: " << stime / ptime << std::endl;
    }
  }
}

TEST(RADIX_BATCHER, TEST_3) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (log2(size) == static_cast<int>(log2(size))) {
    double *vec, *vec_p, *vec_s;
    double start, end;
    int size_v = pow(2, 10);
    if (rank == 0) {
      std::cout << "Size: " << size_v << std::endl;
      vec = getRandomVector(size_v);
      vec_p = new double[size_v];
      vec_s = new double[size_v];
      for (int i = 0; i < size_v; i++) {
        vec_p[i] = vec[i];
        vec_s[i] = vec[i];
      }
    }
    start = MPI_Wtime();
    RadixSortParallel(&vec_p, size_v);
    end = MPI_Wtime();
    if (rank == 0) {
      double ptime = end - start;
      start = MPI_Wtime();
      floatRadixSort<double>(&vec_s, size_v);
      end = MPI_Wtime();
      double stime = end - start;
      for (int i = 0; i < size_v; i++) {
        EXPECT_DOUBLE_EQ(vec_p[i], vec_s[i]);
        // std::cout << vec[i] << " " << vec_s[i] << std::endl;
      }
      std::cout << "Parallel: " << ptime << " Sequential: " << stime
                << std::endl;
      std::cout << "Speedup: " << stime / ptime << std::endl;
    }
  }
}

TEST(RADIX_BATCHER, TEST_4) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (log2(size) == static_cast<int>(log2(size))) {
    double *vec, *vec_p, *vec_s;
    double start, end;
    int size_v = pow(2, 11);
    if (rank == 0) {
      std::cout << "Size: " << size_v << std::endl;
      vec = getRandomVector(size_v);
      vec_p = new double[size_v];
      vec_s = new double[size_v];
      for (int i = 0; i < size_v; i++) {
        vec_p[i] = vec[i];
        vec_s[i] = vec[i];
      }
    }
    start = MPI_Wtime();
    RadixSortParallel(&vec_p, size_v);
    end = MPI_Wtime();
    if (rank == 0) {
      double ptime = end - start;
      start = MPI_Wtime();
      floatRadixSort<double>(&vec_s, size_v);
      end = MPI_Wtime();
      double stime = end - start;
      for (int i = 0; i < size_v; i++) {
        EXPECT_DOUBLE_EQ(vec_p[i], vec_s[i]);
      }
      std::cout << "Parallel: " << ptime << " Sequential: " << stime
                << std::endl;
      std::cout << "Speedup: " << stime / ptime << std::endl;
    }
  }
}

TEST(RADIX_BATCHER, TEST_5) {
  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  if (log2(size) == static_cast<int>(log2(size))) {
    double *vec, *vec_p, *vec_s;
    double start, end;
    int size_v = pow(2, 12);
    if (rank == 0) {
      std::cout << "Size: " << size_v << std::endl;
      vec = getRandomVector(size_v);
      vec_p = new double[size_v];
      vec_s = new double[size_v];
      for (int i = 0; i < size_v; i++) {
        vec_p[i] = vec[i];
        vec_s[i] = vec[i];
      }
    }
    start = MPI_Wtime();
    RadixSortParallel(&vec_p, size_v);
    end = MPI_Wtime();
    if (rank == 0) {
      double ptime = end - start;
      start = MPI_Wtime();
      floatRadixSort<double>(&vec_s, size_v);
      end = MPI_Wtime();
      double stime = end - start;
      for (int i = 0; i < size_v; i++) {
        EXPECT_DOUBLE_EQ(vec_p[i], vec_s[i]);
        // std::cout << vec[i] << " " << vec_s[i] << std::endl;
      }
      std::cout << "Parallel: " << ptime << " Sequential: " << stime
                << std::endl;
      std::cout << "Speedup: " << stime / ptime << std::endl;
    }
  }
}

int main(int argc, char **argv) {
  ::testing::InitGoogleTest(&argc, argv);
  MPI_Init(&argc, &argv);

  ::testing::AddGlobalTestEnvironment(new GTestMPIListener::MPIEnvironment);
  ::testing::TestEventListeners &listeners =
      ::testing::UnitTest::GetInstance()->listeners();

  listeners.Release(listeners.default_result_printer());
  listeners.Release(listeners.default_xml_generator());

  listeners.Append(new GTestMPIListener::MPIMinimalistPrinter);
  return RUN_ALL_TESTS();
}
\end{lstlisting}
\end{document}
